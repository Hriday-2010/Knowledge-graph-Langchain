{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --quiet langchain langchain-community langchain-groq neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"neo4j+s://567644e8.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"j3dGBv4YmZk9mNM45MlDxx99FIUaT0bv3IhrLuOPd9c\"\n",
    "AURA_INSTANCEID=\"567644e8\"\n",
    "AURA_INSTANCENAME=\"Instance01\"\n",
    "groq_api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NEO4J_URI\"]=NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"]=NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"]=NEO4J_PASSWORD\n",
    "os.environ[\"GROQ_API_KEY\"]=groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x1077f0810>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x16833ddd0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x16833f650>, model_name='gemma2-9b-it', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"\\nTime series forecasting is an active research area that has drawn considerable attention for applications in variety of areas. With the time series approach to forecasting, historical observations of the same variable are analyzed to develop a model describing the underlying relationship. Then the established model is used in order to extrapolate the time series into the future. This modeling approach is particularly useful when little knowledge is available on the underlying data generating process or when there is no sat- isfactory explanatory model that relates the prediction variable to other explanatory variables. Over the past several decades, much effort has been devoted to the development and improvement of time series forecasting models [1].\\nArtificial neural networks (ANNs) are one of the most important types of nonparametric nonlinear time series models, which have been proposed and examined for time series forecasting. The basic\\nabstract\\nImproving forecasting especially time series forecasting accuracy is an important yet often difficult task facing decision makers in many areas. Both theoretical and empirical findings have indicated that inte- gration of different models can be an effective way of improving upon their predictive performance, especially when the models in combination are quite different. Artificial neural networks (ANNs) are flexible computing frameworks and universal approximators that can be applied to a wide range of fore- casting problems with a high degree of accuracy. However, using ANNs to model linear problems have yielded mixed results, and hence; it is not wise to apply ANNs blindly to any type of data. Autoregressive integrated moving average (ARIMA) models are one of the most popular linear models in time series forecasting, which have been widely applied in order to construct more accurate hybrid models during the past decade. Although, hybrid techniques, which decompose a time series into its linear and nonlinear components, have recently been shown to be successful for single models, these models have some disad- vantages. In this paper, a novel hybridization of artificial neural networks and ARIMA model is proposed in order to overcome mentioned limitation of ANNs and yield more general and more accurate forecast- ing model than traditional hybrid ARIMA-ANNs models. In our proposed model, the unique advantages of ARIMA models in linear modeling are used in order to identify and magnify the existing linear struc- ture in data, and then a neural network is used in order to determine a model to capture the underlying data generating process and predict, using preprocessed data. Empirical results with three well-known real data sets indicate that the proposed model can be an effective way to improve forecasting accuracy achieved by traditional hybrid models and also either of the components models used separately.\\n\\nattention in time series forecasting. Artificial neural networks have been found to be a viable contender to various traditional time series models. Lapedes and Farber [9] report the first attempt to model nonlinear time series with artificial neural networks. De Groot and Wurtz [10] present a detailed analysis of univari- ate time series forecasting using feedforward neural networks for two benchmark nonlinear time series. Chakraborty et al. [11] con- duct an empirical study on multivariate time series forecasting with artificial neural networks. Poli and Jones [12] propose a stochastic neural network model based on Kalman filter for nonlinear time series prediction. Cottrell et al. [13] address the issue of network structure for forecasting real world time series. Berardi and Zhang [14] investigate the bias and variance issue in the time series fore- casting context. In addition, several large forecasting competitions [15,16] suggest that neural networks can be a very useful addition to the time series forecasting toolbox.\\nAlthough ANNs have the advantages of accurate forecasting, their performance in some specific situation is inconsistent. In the literature, several papers are devoted to comparing ANNs with the traditional methods [1]. Despite the numerous studies, which have shown ANNs are significantly better than the conventional lin- ear models and their forecast considerably and consistently more accurately, some other studies have reported inconsistent results. Foster et al. [17] find that ANNs are significantly inferior to linear regression and a simple average of exponential smoothing meth- ods. Brace et al. [18] also find that the performance of ANNs is not as good as many other statistical methods commonly used in the load forecasting. Denton [19] with generated data for several dif- ferent experimental conditions shows that under ideal conditions, with all regression assumptions, there is little difference in the pre- dictability between ANNs and linear regression, and only under less ideal conditions such as outliers, multicollinearity, and model mis- specification, ANNs perform better. Hann and Steurer [20] make comparisons between the neural networks and the linear model in exchange rate forecasting. They report that if monthly data are used, neural networks do not show much improvement over lin- ear models. Taskaya and Casey [21] compare the performance of linear models with neural networks. Their results show that linear autoregressive models can outperform neural networks in some cases.\\nMost other researchers also make comparisons between ANNs and the corresponding traditional methods in their particular appli- cations. De Groot and Wurtz [10] compare ANNs with the linear (Box-Jenkins) and nonlinear (bilinear and TAR) statistical models in forecasting the sunspots data. Fishwick [22] reports that the perfor- mance of ANNs is worse than that of the simple linear regression. Tang et al. [23], and Tang and Fishwick try to answer the question: under what conditions ANN forecasters can perform better than the linear time series forecasting methods such as Box-Jenkins mod- els [24]. Some researchers believe that in some specific situations where ANNs perform worse than linear statistical models, the rea- son may simply be that the data is linear without much disturbance, therefore; cannot be expected that ANNs to do better than linear models for linear relationships [1]. However, for any reason, using ANNs to model linear problems have yielded mixed results and hence; it is not wise to apply ANNs blindly to any type of data.\\nIn the literature, several linear approaches have been proposed to time series forecasting. Autoregressive integrated moving aver- age (ARIMA) models are one of the most popular linear models for time series forecasting over the past three decades that have enjoyed useful applications in forecasting social, economic, engi- neering, foreign exchange, and stock problems. ARIMA models have been originated from the autoregressive models (AR), the moving average models (MA) and the combination of the AR and MA, the ARMA models. ARIMA models can be used when the time series is stationary and there is no missing data in the within the time series\\n[25]. In ARIMA analysis, an identified underlying process is gener- ated based on observations to a time series for generating a good model that shows the process-generating mechanism precisely.\\nBox and Jenkins [26] provided a step-by-step procedure for ARMA analysis, which is a combination of AR coefficients, which are multiplied by past values of the time series data and MA coeffi- cients, which are multiplied by past random shocks. The popularity of the ARIMA model is due to its statistical properties as well as the well-known Box-Jenkins methodology in the model building process. In addition, ARIMA models [22] can implement various exponential smoothing models. Although ARIMA models are quite flexible in that they can represent several different types of time series, their major limitation is the pre-assumed linear form of the model. ARIMA models assume that future values of a time series have a linear relationship with current and past values as well as with white noise, so approximations by ARIMA models may not be adequate for complex nonlinear real-world problems. However, real world systems are often nonlinear [1], thus, it is unreason- able to assume that a particular realization of a given time series is generated by a linear process.\\nBoth ANNs and ARIMA models have achieved successes in their own linear or nonlinear domains. However, none of them is a universal model that is suitable for all circumstances. The approxi- mation of ARIMA models to complex nonlinear problems as well as ANNs to model linear problems may be totally inappropriate, and also, in problems that consist both linear and nonlinear correlation structures. Using hybrid models or combining several models has become a common practice in order to overcome the limitations of components models and improve the forecasting accuracy. In addi- tion, since it is difficult to completely know the characteristics of the data in a real problem, hybrid methodology that has both lin- ear and nonlinear modeling capabilities can be a good strategy for practical use.\\nThe hybrid techniques that decompose a time series into its lin- ear and nonlinear form are one of the most popular hybrid models categories, which have been shown to be successful for single mod- els. Zhang [27] presented a hybrid ARIMA and ANN approaches for time series forecasting using mentioned technique. In Zhang'ArithmeticErrors hybrid model is jointly used the linear ARIMA and the nonlinear multilayer perceptrons models in order to capture different forms of relationship in the time series data. The motivation of Zhang's hybrid model comes from the following perspectives. First, it is often difficult in practice to determine whether a time series under study is generated from a linear or nonlinear underlying process; thus, the problem of model selection can be eased by combining linear ARIMA and nonlinear ANN models. Second, real-world time series are rarely pure linear or nonlinear and often contain both linear and nonlinear patterns, which neither ARIMA nor ANN mod- els alone can be adequate for modeling in such cases; hence the problem of modeling the combined linear and nonlinear autocor- relation structures in time series can be solved by combining linear ARIMA and nonlinear ANN models. Third, it is almost universally agreed in the forecasting literature that no single model is the best in every situation, due to the fact that a real-world problem is often complex in nature and any single model may not be able to cap- ture different patterns equally well. Therefore, the chance in order to capture different patterns in the data can be increased by com- bining different models. These hybrid models, despite the all their advantages, have two assumptions [21] that will degenerate their performance if the opposite situation occurs; therefore, they may be inadequate in some specific situations.\\nIn this paper, ARIMA models are applied to construct a new hybrid model in order to overcome the above-mentioned limita- tion of artificial neural networks and to yield more general and more accurate model than traditional hybrid ARIMA and artificial neural networks models. In our proposed model, a time series is\\n\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "text=\"\"\"\n",
    "Time series forecasting is an active research area that has drawn considerable attention for applications in variety of areas. With the time series approach to forecasting, historical observations of the same variable are analyzed to develop a model describing the underlying relationship. Then the established model is used in order to extrapolate the time series into the future. This modeling approach is particularly useful when little knowledge is available on the underlying data generating process or when there is no sat- isfactory explanatory model that relates the prediction variable to other explanatory variables. Over the past several decades, much effort has been devoted to the development and improvement of time series forecasting models [1].\n",
    "Artificial neural networks (ANNs) are one of the most important types of nonparametric nonlinear time series models, which have been proposed and examined for time series forecasting. The basic\n",
    "abstract\n",
    "Improving forecasting especially time series forecasting accuracy is an important yet often difficult task facing decision makers in many areas. Both theoretical and empirical findings have indicated that inte- gration of different models can be an effective way of improving upon their predictive performance, especially when the models in combination are quite different. Artificial neural networks (ANNs) are flexible computing frameworks and universal approximators that can be applied to a wide range of fore- casting problems with a high degree of accuracy. However, using ANNs to model linear problems have yielded mixed results, and hence; it is not wise to apply ANNs blindly to any type of data. Autoregressive integrated moving average (ARIMA) models are one of the most popular linear models in time series forecasting, which have been widely applied in order to construct more accurate hybrid models during the past decade. Although, hybrid techniques, which decompose a time series into its linear and nonlinear components, have recently been shown to be successful for single models, these models have some disad- vantages. In this paper, a novel hybridization of artificial neural networks and ARIMA model is proposed in order to overcome mentioned limitation of ANNs and yield more general and more accurate forecast- ing model than traditional hybrid ARIMA-ANNs models. In our proposed model, the unique advantages of ARIMA models in linear modeling are used in order to identify and magnify the existing linear struc- ture in data, and then a neural network is used in order to determine a model to capture the underlying data generating process and predict, using preprocessed data. Empirical results with three well-known real data sets indicate that the proposed model can be an effective way to improve forecasting accuracy achieved by traditional hybrid models and also either of the components models used separately.\n",
    "\n",
    "attention in time series forecasting. Artificial neural networks have been found to be a viable contender to various traditional time series models. Lapedes and Farber [9] report the first attempt to model nonlinear time series with artificial neural networks. De Groot and Wurtz [10] present a detailed analysis of univari- ate time series forecasting using feedforward neural networks for two benchmark nonlinear time series. Chakraborty et al. [11] con- duct an empirical study on multivariate time series forecasting with artificial neural networks. Poli and Jones [12] propose a stochastic neural network model based on Kalman filter for nonlinear time series prediction. Cottrell et al. [13] address the issue of network structure for forecasting real world time series. Berardi and Zhang [14] investigate the bias and variance issue in the time series fore- casting context. In addition, several large forecasting competitions [15,16] suggest that neural networks can be a very useful addition to the time series forecasting toolbox.\n",
    "Although ANNs have the advantages of accurate forecasting, their performance in some specific situation is inconsistent. In the literature, several papers are devoted to comparing ANNs with the traditional methods [1]. Despite the numerous studies, which have shown ANNs are significantly better than the conventional lin- ear models and their forecast considerably and consistently more accurately, some other studies have reported inconsistent results. Foster et al. [17] find that ANNs are significantly inferior to linear regression and a simple average of exponential smoothing meth- ods. Brace et al. [18] also find that the performance of ANNs is not as good as many other statistical methods commonly used in the load forecasting. Denton [19] with generated data for several dif- ferent experimental conditions shows that under ideal conditions, with all regression assumptions, there is little difference in the pre- dictability between ANNs and linear regression, and only under less ideal conditions such as outliers, multicollinearity, and model mis- specification, ANNs perform better. Hann and Steurer [20] make comparisons between the neural networks and the linear model in exchange rate forecasting. They report that if monthly data are used, neural networks do not show much improvement over lin- ear models. Taskaya and Casey [21] compare the performance of linear models with neural networks. Their results show that linear autoregressive models can outperform neural networks in some cases.\n",
    "Most other researchers also make comparisons between ANNs and the corresponding traditional methods in their particular appli- cations. De Groot and Wurtz [10] compare ANNs with the linear (Box-Jenkins) and nonlinear (bilinear and TAR) statistical models in forecasting the sunspots data. Fishwick [22] reports that the perfor- mance of ANNs is worse than that of the simple linear regression. Tang et al. [23], and Tang and Fishwick try to answer the question: under what conditions ANN forecasters can perform better than the linear time series forecasting methods such as Box-Jenkins mod- els [24]. Some researchers believe that in some specific situations where ANNs perform worse than linear statistical models, the rea- son may simply be that the data is linear without much disturbance, therefore; cannot be expected that ANNs to do better than linear models for linear relationships [1]. However, for any reason, using ANNs to model linear problems have yielded mixed results and hence; it is not wise to apply ANNs blindly to any type of data.\n",
    "In the literature, several linear approaches have been proposed to time series forecasting. Autoregressive integrated moving aver- age (ARIMA) models are one of the most popular linear models for time series forecasting over the past three decades that have enjoyed useful applications in forecasting social, economic, engi- neering, foreign exchange, and stock problems. ARIMA models have been originated from the autoregressive models (AR), the moving average models (MA) and the combination of the AR and MA, the ARMA models. ARIMA models can be used when the time series is stationary and there is no missing data in the within the time series\n",
    "[25]. In ARIMA analysis, an identified underlying process is gener- ated based on observations to a time series for generating a good model that shows the process-generating mechanism precisely.\n",
    "Box and Jenkins [26] provided a step-by-step procedure for ARMA analysis, which is a combination of AR coefficients, which are multiplied by past values of the time series data and MA coeffi- cients, which are multiplied by past random shocks. The popularity of the ARIMA model is due to its statistical properties as well as the well-known Box-Jenkins methodology in the model building process. In addition, ARIMA models [22] can implement various exponential smoothing models. Although ARIMA models are quite flexible in that they can represent several different types of time series, their major limitation is the pre-assumed linear form of the model. ARIMA models assume that future values of a time series have a linear relationship with current and past values as well as with white noise, so approximations by ARIMA models may not be adequate for complex nonlinear real-world problems. However, real world systems are often nonlinear [1], thus, it is unreason- able to assume that a particular realization of a given time series is generated by a linear process.\n",
    "Both ANNs and ARIMA models have achieved successes in their own linear or nonlinear domains. However, none of them is a universal model that is suitable for all circumstances. The approxi- mation of ARIMA models to complex nonlinear problems as well as ANNs to model linear problems may be totally inappropriate, and also, in problems that consist both linear and nonlinear correlation structures. Using hybrid models or combining several models has become a common practice in order to overcome the limitations of components models and improve the forecasting accuracy. In addi- tion, since it is difficult to completely know the characteristics of the data in a real problem, hybrid methodology that has both lin- ear and nonlinear modeling capabilities can be a good strategy for practical use.\n",
    "The hybrid techniques that decompose a time series into its lin- ear and nonlinear form are one of the most popular hybrid models categories, which have been shown to be successful for single mod- els. Zhang [27] presented a hybrid ARIMA and ANN approaches for time series forecasting using mentioned technique. In Zhang'ArithmeticErrors hybrid model is jointly used the linear ARIMA and the nonlinear multilayer perceptrons models in order to capture different forms of relationship in the time series data. The motivation of Zhang's hybrid model comes from the following perspectives. First, it is often difficult in practice to determine whether a time series under study is generated from a linear or nonlinear underlying process; thus, the problem of model selection can be eased by combining linear ARIMA and nonlinear ANN models. Second, real-world time series are rarely pure linear or nonlinear and often contain both linear and nonlinear patterns, which neither ARIMA nor ANN mod- els alone can be adequate for modeling in such cases; hence the problem of modeling the combined linear and nonlinear autocor- relation structures in time series can be solved by combining linear ARIMA and nonlinear ANN models. Third, it is almost universally agreed in the forecasting literature that no single model is the best in every situation, due to the fact that a real-world problem is often complex in nature and any single model may not be able to cap- ture different patterns equally well. Therefore, the chance in order to capture different patterns in the data can be increased by com- bining different models. These hybrid models, despite the all their advantages, have two assumptions [21] that will degenerate their performance if the opposite situation occurs; therefore, they may be inadequate in some specific situations.\n",
    "In this paper, ARIMA models are applied to construct a new hybrid model in order to overcome the above-mentioned limita- tion of artificial neural networks and to yield more general and more accurate model than traditional hybrid ARIMA and artificial neural networks models. In our proposed model, a time series is\n",
    "\"\"\"\n",
    "documents=[Document(page_content=text)]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer=LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_docs=llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphDocument(nodes=[Node(id='Time Series Forecasting', type='Process'), Node(id='Artificial Neural Networks', type='Model'), Node(id='Autoregressive Integrated Moving Average (Arima)', type='Model'), Node(id='Linear Models', type='Model'), Node(id='Nonlinear Models', type='Model'), Node(id='Hybrid Models', type='Model')], relationships=[Relationship(source=Node(id='Time Series Forecasting', type='Process'), target=Node(id='Artificial Neural Networks', type='Model'), type='USED_FOR'), Relationship(source=Node(id='Time Series Forecasting', type='Process'), target=Node(id='Autoregressive Integrated Moving Average (Arima)', type='Model'), type='USED_FOR'), Relationship(source=Node(id='Artificial Neural Networks', type='Model'), target=Node(id='Linear Models', type='Model'), type='SUB_TYPE_OF'), Relationship(source=Node(id='Artificial Neural Networks', type='Model'), target=Node(id='Nonlinear Models', type='Model'), type='SUB_TYPE_OF'), Relationship(source=Node(id='Hybrid Models', type='Model'), target=Node(id='Linear Models', type='Model'), type='COMBINATION_OF'), Relationship(source=Node(id='Hybrid Models', type='Model'), target=Node(id='Nonlinear Models', type='Model'), type='COMBINATION_OF')], source=Document(page_content=\"\\nTime series forecasting is an active research area that has drawn considerable attention for applications in variety of areas. With the time series approach to forecasting, historical observations of the same variable are analyzed to develop a model describing the underlying relationship. Then the established model is used in order to extrapolate the time series into the future. This modeling approach is particularly useful when little knowledge is available on the underlying data generating process or when there is no sat- isfactory explanatory model that relates the prediction variable to other explanatory variables. Over the past several decades, much effort has been devoted to the development and improvement of time series forecasting models [1].\\nArtificial neural networks (ANNs) are one of the most important types of nonparametric nonlinear time series models, which have been proposed and examined for time series forecasting. The basic\\nabstract\\nImproving forecasting especially time series forecasting accuracy is an important yet often difficult task facing decision makers in many areas. Both theoretical and empirical findings have indicated that inte- gration of different models can be an effective way of improving upon their predictive performance, especially when the models in combination are quite different. Artificial neural networks (ANNs) are flexible computing frameworks and universal approximators that can be applied to a wide range of fore- casting problems with a high degree of accuracy. However, using ANNs to model linear problems have yielded mixed results, and hence; it is not wise to apply ANNs blindly to any type of data. Autoregressive integrated moving average (ARIMA) models are one of the most popular linear models in time series forecasting, which have been widely applied in order to construct more accurate hybrid models during the past decade. Although, hybrid techniques, which decompose a time series into its linear and nonlinear components, have recently been shown to be successful for single models, these models have some disad- vantages. In this paper, a novel hybridization of artificial neural networks and ARIMA model is proposed in order to overcome mentioned limitation of ANNs and yield more general and more accurate forecast- ing model than traditional hybrid ARIMA-ANNs models. In our proposed model, the unique advantages of ARIMA models in linear modeling are used in order to identify and magnify the existing linear struc- ture in data, and then a neural network is used in order to determine a model to capture the underlying data generating process and predict, using preprocessed data. Empirical results with three well-known real data sets indicate that the proposed model can be an effective way to improve forecasting accuracy achieved by traditional hybrid models and also either of the components models used separately.\\n\\nattention in time series forecasting. Artificial neural networks have been found to be a viable contender to various traditional time series models. Lapedes and Farber [9] report the first attempt to model nonlinear time series with artificial neural networks. De Groot and Wurtz [10] present a detailed analysis of univari- ate time series forecasting using feedforward neural networks for two benchmark nonlinear time series. Chakraborty et al. [11] con- duct an empirical study on multivariate time series forecasting with artificial neural networks. Poli and Jones [12] propose a stochastic neural network model based on Kalman filter for nonlinear time series prediction. Cottrell et al. [13] address the issue of network structure for forecasting real world time series. Berardi and Zhang [14] investigate the bias and variance issue in the time series fore- casting context. In addition, several large forecasting competitions [15,16] suggest that neural networks can be a very useful addition to the time series forecasting toolbox.\\nAlthough ANNs have the advantages of accurate forecasting, their performance in some specific situation is inconsistent. In the literature, several papers are devoted to comparing ANNs with the traditional methods [1]. Despite the numerous studies, which have shown ANNs are significantly better than the conventional lin- ear models and their forecast considerably and consistently more accurately, some other studies have reported inconsistent results. Foster et al. [17] find that ANNs are significantly inferior to linear regression and a simple average of exponential smoothing meth- ods. Brace et al. [18] also find that the performance of ANNs is not as good as many other statistical methods commonly used in the load forecasting. Denton [19] with generated data for several dif- ferent experimental conditions shows that under ideal conditions, with all regression assumptions, there is little difference in the pre- dictability between ANNs and linear regression, and only under less ideal conditions such as outliers, multicollinearity, and model mis- specification, ANNs perform better. Hann and Steurer [20] make comparisons between the neural networks and the linear model in exchange rate forecasting. They report that if monthly data are used, neural networks do not show much improvement over lin- ear models. Taskaya and Casey [21] compare the performance of linear models with neural networks. Their results show that linear autoregressive models can outperform neural networks in some cases.\\nMost other researchers also make comparisons between ANNs and the corresponding traditional methods in their particular appli- cations. De Groot and Wurtz [10] compare ANNs with the linear (Box-Jenkins) and nonlinear (bilinear and TAR) statistical models in forecasting the sunspots data. Fishwick [22] reports that the perfor- mance of ANNs is worse than that of the simple linear regression. Tang et al. [23], and Tang and Fishwick try to answer the question: under what conditions ANN forecasters can perform better than the linear time series forecasting methods such as Box-Jenkins mod- els [24]. Some researchers believe that in some specific situations where ANNs perform worse than linear statistical models, the rea- son may simply be that the data is linear without much disturbance, therefore; cannot be expected that ANNs to do better than linear models for linear relationships [1]. However, for any reason, using ANNs to model linear problems have yielded mixed results and hence; it is not wise to apply ANNs blindly to any type of data.\\nIn the literature, several linear approaches have been proposed to time series forecasting. Autoregressive integrated moving aver- age (ARIMA) models are one of the most popular linear models for time series forecasting over the past three decades that have enjoyed useful applications in forecasting social, economic, engi- neering, foreign exchange, and stock problems. ARIMA models have been originated from the autoregressive models (AR), the moving average models (MA) and the combination of the AR and MA, the ARMA models. ARIMA models can be used when the time series is stationary and there is no missing data in the within the time series\\n[25]. In ARIMA analysis, an identified underlying process is gener- ated based on observations to a time series for generating a good model that shows the process-generating mechanism precisely.\\nBox and Jenkins [26] provided a step-by-step procedure for ARMA analysis, which is a combination of AR coefficients, which are multiplied by past values of the time series data and MA coeffi- cients, which are multiplied by past random shocks. The popularity of the ARIMA model is due to its statistical properties as well as the well-known Box-Jenkins methodology in the model building process. In addition, ARIMA models [22] can implement various exponential smoothing models. Although ARIMA models are quite flexible in that they can represent several different types of time series, their major limitation is the pre-assumed linear form of the model. ARIMA models assume that future values of a time series have a linear relationship with current and past values as well as with white noise, so approximations by ARIMA models may not be adequate for complex nonlinear real-world problems. However, real world systems are often nonlinear [1], thus, it is unreason- able to assume that a particular realization of a given time series is generated by a linear process.\\nBoth ANNs and ARIMA models have achieved successes in their own linear or nonlinear domains. However, none of them is a universal model that is suitable for all circumstances. The approxi- mation of ARIMA models to complex nonlinear problems as well as ANNs to model linear problems may be totally inappropriate, and also, in problems that consist both linear and nonlinear correlation structures. Using hybrid models or combining several models has become a common practice in order to overcome the limitations of components models and improve the forecasting accuracy. In addi- tion, since it is difficult to completely know the characteristics of the data in a real problem, hybrid methodology that has both lin- ear and nonlinear modeling capabilities can be a good strategy for practical use.\\nThe hybrid techniques that decompose a time series into its lin- ear and nonlinear form are one of the most popular hybrid models categories, which have been shown to be successful for single mod- els. Zhang [27] presented a hybrid ARIMA and ANN approaches for time series forecasting using mentioned technique. In Zhang'ArithmeticErrors hybrid model is jointly used the linear ARIMA and the nonlinear multilayer perceptrons models in order to capture different forms of relationship in the time series data. The motivation of Zhang's hybrid model comes from the following perspectives. First, it is often difficult in practice to determine whether a time series under study is generated from a linear or nonlinear underlying process; thus, the problem of model selection can be eased by combining linear ARIMA and nonlinear ANN models. Second, real-world time series are rarely pure linear or nonlinear and often contain both linear and nonlinear patterns, which neither ARIMA nor ANN mod- els alone can be adequate for modeling in such cases; hence the problem of modeling the combined linear and nonlinear autocor- relation structures in time series can be solved by combining linear ARIMA and nonlinear ANN models. Third, it is almost universally agreed in the forecasting literature that no single model is the best in every situation, due to the fact that a real-world problem is often complex in nature and any single model may not be able to cap- ture different patterns equally well. Therefore, the chance in order to capture different patterns in the data can be increased by com- bining different models. These hybrid models, despite the all their advantages, have two assumptions [21] that will degenerate their performance if the opposite situation occurs; therefore, they may be inadequate in some specific situations.\\nIn this paper, ARIMA models are applied to construct a new hybrid model in order to overcome the above-mentioned limita- tion of artificial neural networks and to yield more general and more accurate model than traditional hybrid ARIMA and artificial neural networks models. In our proposed model, a time series is\\n\"))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_docs[0].relationships\n",
    "# graph_docs[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\n",
    "\n",
    "MERGE(m:Movie{id:row.movieId})\n",
    "SET m.released = date(row.released),\n",
    "    m.title = row.title,\n",
    "    m.imdbRating = toFloat(row.imdbRating)\n",
    "FOREACH (director in split(row.director, '|') |\n",
    "    MERGE (p:Person {name:trim(director)})\n",
    "    MERGE (p)-[:DIRECTED]->(m))\n",
    "FOREACH (actor in split(row.actors, '|') |\n",
    "    MERGE (p:Person {name:trim(actor)})\n",
    "    MERGE (p)-[:ACTED_IN]->(m))\n",
    "FOREACH (genre in split(row.genres, '|') |\n",
    "    MERGE (g:Genre {name:trim(genre)})\n",
    "    MERGE (m)-[:IN_GENRE]->(g))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from groq import Groq\n",
    "\n",
    "# client = Groq()\n",
    "# completion = client.chat.completions.create(\n",
    "#     model=\"gemma2-9b-it\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": text+\"generate me a query for neo4j \\n\"\n",
    "#         }\n",
    "#     ],\n",
    "#     temperature=1,\n",
    "#     max_tokens=1024,\n",
    "#     top_p=1,\n",
    "#     stream=True,\n",
    "#     stop=None,\n",
    "# )\n",
    "\n",
    "# for chunk in completion:\n",
    "#     print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Movie {id: STRING, released: DATE, title: STRING, imdbRating: FLOAT}\n",
      "Person {name: STRING}\n",
      "Genre {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Movie)-[:IN_GENRE]->(:Genre)\n",
      "(:Person)-[:DIRECTED]->(:Movie)\n",
      "(:Person)-[:ACTED_IN]->(:Movie)\n"
     ]
    }
   ],
   "source": [
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=GraphCypherQAChain.from_llm(llm,graph=graph,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:DIRECTED]->(m:Movie) RETURN p.name \n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.name': 'John Lasseter'}, {'p.name': 'Joe Johnston'}, {'p.name': 'Howard Deutch'}, {'p.name': 'Forest Whitaker'}, {'p.name': 'Charles Shyer'}, {'p.name': 'Michael Mann'}, {'p.name': 'Sydney Pollack'}, {'p.name': 'Peter Hewitt'}, {'p.name': 'Peter Hyams'}, {'p.name': 'Martin Campbell'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"query\":\"who are the directors?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
